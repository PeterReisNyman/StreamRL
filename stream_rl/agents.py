import asyncio
from collections import defaultdict
from typing import List, Dict, Generator

class BigramModel:
    """Simple bigram model for token generation."""
    def __init__(self):
        self.counts: Dict[str, Dict[str, int]] = defaultdict(lambda: defaultdict(int))
        self.totals: Dict[str, int] = defaultdict(int)

    def update(self, tokens: List[str]) -> None:
        prev = "<s>"
        for token in tokens:
            self.counts[prev][token] += 1
            self.totals[prev] += 1
            prev = token
        self.counts[prev]["</s>"] += 1
        self.totals[prev] += 1

    def next_token(self, prev: str) -> str:
        choices = self.counts.get(prev)
        if not choices:
            return "</s>"
        total = self.totals[prev]
        # Simple argmax choice
        token = max(choices.items(), key=lambda x: x[1])[0]
        return token

    def generate(self, max_tokens: int = 20) -> List[str]:
        tokens = []
        prev = "<s>"
        for _ in range(max_tokens):
            token = self.next_token(prev)
            if token == "</s>":
                break
            tokens.append(token)
            prev = token
        return tokens

class Agent:
    def __init__(self, name: str, system_message: str):
        self.name = name
        self.system_message = system_message
        self.model = BigramModel()

    async def generate_stream(self, task: str, delay: float = 0.1) -> Generator[str, None, None]:
        """Stream tokens generated by the model."""
        tokens = self.model.generate()
        if not tokens:
            # Fallback to echoing the task split into tokens
            tokens = [task[i:i+3] for i in range(0, len(task), 3)]
        for token in tokens:
            await asyncio.sleep(delay)
            yield token

    def train(self, tokens: List[str]) -> None:
        self.model.update(tokens)
